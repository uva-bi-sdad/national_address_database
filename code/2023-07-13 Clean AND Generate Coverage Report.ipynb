{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import matplotlib as mpl\n",
    "# from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Empty (Go through each county. If there is a file, join on geoid, if there is not, create empty columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221\n"
     ]
    }
   ],
   "source": [
    "prefix = 'https://www2.census.gov/geo/tiger/TIGER2020PL/LAYER/TABBLOCK/2020/'\n",
    "r= requests.get(prefix)\n",
    "soup = BeautifulSoup(r.content)\n",
    "valid_zips = {}\n",
    "\n",
    "for a in soup.find_all('a', href=True):\n",
    "    if not '.zip' in a['href'] or len(a['href'])!= 28: # filter for the entire state ones\n",
    "        continue\n",
    "    valid_zips[a['href'].split('_')[2]] = prefix+a['href']\n",
    "print(len(valid_zips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72153 geoid length same, skipping: 100%|█████████████████████████| 3221/3221 [30:00<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(valid_zips)\n",
    "i = 0\n",
    "for county in pbar:\n",
    "    i+= 1\n",
    "    if i < 2188:\n",
    "        continue\n",
    "#     if os.path.isfile('../data/address/%s.csv.xz' % county):\n",
    "#         # skip if file already exists\n",
    "#         continue\n",
    "        \n",
    "    county_shape_df = gpd.read_file(valid_zips[county])    \n",
    "    if os.path.isfile('../data/address/%s.csv.xz' % county):\n",
    "        cdf = pd.read_csv('../data/address/%s.csv.xz' % county, dtype={'GEOID20':object})\n",
    "        \n",
    "        # Skip if the length is already the same\n",
    "        if len(cdf['GEOID20'].unique()) == len(county_shape_df['GEOID20'].unique()):\n",
    "            pbar.set_description('%s geoid length same, skipping' % county)\n",
    "            continue\n",
    "        pbar.set_description('%s geoid not the same, merging' % county)\n",
    "        mdf = pd.merge(cdf,county_shape_df[['GEOID20']],on='GEOID20', how='right') # create empty rows based on authority shape fiels\n",
    "    else:\n",
    "        mdf = county_shape_df[['GEOID20']]\n",
    "        pbar.set_description('%s address not found, adding' % county)\n",
    "    mdf = mdf.reindex(columns= ['address', 'GEOID20', 'longitude', 'latitude'])\n",
    "    \n",
    "    # Fail if the lengths are not the same\n",
    "    assert len(mdf['GEOID20'].unique()) == len(county_shape_df['GEOID20'].unique()), print('%s: %s' % (len(mdf['GEOID20'].unique()), len(county_shape_df['GEOID20'].unique())))\n",
    "    pbar.set_description('%s length of file same, saving' % county)\n",
    "    mdf.to_csv('../data/address/%s.csv.xz' % county, index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 3221/3221 [02:41<00:00, 19.96it/s]\n"
     ]
    }
   ],
   "source": [
    "df['address_count'] = df['address'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "tdf = df.groupby('GEOID20')['address_count'].sum().reset_index()\n",
    "assert df['GEOID20'].unique().size == len(tdf) # make sure size of unique GEOIDs are the same\n",
    "\n",
    "d = '../data/address'\n",
    "dfs= []\n",
    "\n",
    "for file in tqdm(os.listdir(d)):\n",
    "    df = pd.read_csv(os.path.join(d,file), dtype={'GEOID20': object})\n",
    "    \n",
    "    assert all(df['GEOID20'].map(len)==15), print(file)\n",
    "    \n",
    "    df['address_count'] = df['address'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    report = df.groupby('GEOID20')['address_count'].sum().reset_index()    \n",
    "    dfs.append(report)\n",
    "\n",
    "final_df = pd.concat(dfs)\n",
    "assert len(final_df) == 8174955 # Hard check\n",
    "final_df = final_df.sort_values(by=['GEOID20', 'address_count'])\n",
    "final_df.to_csv('../data/coverage_report.csv.xz', index=False) # save file to report\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
